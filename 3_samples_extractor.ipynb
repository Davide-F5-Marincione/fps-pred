{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WARNING: DO NOT RUN THIS NOTEBOOK FULLY, IT CONTAINS A COUPLE OF CELLS WHICH EXECUTE LONG WINDED PROCESSES\n",
    "\n",
    "In this notebook we extract the raw data from the files (already parsed from .demo (which we couldn't attach to this upload, because they weigh 4.8 GB) to .json).\n",
    "\n",
    "First thing we do is load the graph created in the previous notebook and define a couple of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import kdtree\n",
    "\n",
    "graph = None\n",
    "with open('graph.pickle', 'rb') as handle:\n",
    "    graph = pickle.load(handle)\n",
    "\n",
    "points, _, connect_to, connect_from = graph\n",
    "\n",
    "filenames_dir_train = \"parsed_demos\"\n",
    "middle_result_name_train = \"movements_raw_train.pickle\"\n",
    "final_result_name_train = \"samples_train.pickle\"\n",
    "\n",
    "filenames_dir_test = \"parsed_demos\\\\test\"\n",
    "middle_result_name_test = \"movements_raw_test.pickle\"\n",
    "final_result_name_test = \"samples_test.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define, since the connections are directed, an \"inverse\" of the set of edges, this will be useful later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, since this task is pretty heavy to run, we make use of our *extensive* knowledge of algorithms and data structures to make it such that the stuff we are about to run is not going to be a native algorithm.\n",
    "\n",
    "Just for knowledge: k-d-trees are data structures (mostly used in 3d graphics and physics simulations) which make collision-checking between multiple agents much faster since they exploit the location of the objects to return the possible colliding ones.\n",
    "\n",
    "The kdtree import we are making is for a .py file we wrote ourselves, the implementation is quite naive, but effective nonetheless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kdtree\n",
    "\n",
    "data_struct = kdtree.construct_2d_tree([(point[0], point[1], point[2], i) for i,point in enumerate(points)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load all of the .jsons we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading astralis-vs-g2-m1-dust2.json\n",
      "Loading catevil-vs-nexga-dust2.json\n",
      "Loading ence-vs-faze-m4-dust2.json\n",
      "Loading faze-vs-big-m1-dust2.json\n",
      "Loading g2-vs-spirit-dust2.json\n",
      "Loading natus-vincere-vs-faze-m2-dust2.json\n",
      "Loading outsiders-vs-big-dust2.json\n",
      "Loading players-vs-astralis-m2-dust2.json\n",
      "Loading vitality-vs-mouz-m2-dust2.json\n",
      "Loading vitality-vs-outsiders-m1-dust2.json\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(filenames_dir_train)\n",
    "\n",
    "datas = dict()\n",
    "\n",
    "for filename in filenames:\n",
    "    name, ext = os.path.splitext(filename)\n",
    "\n",
    "    if ext != \".json\":\n",
    "        continue\n",
    "\n",
    "    print(f\"Loading {filename}\")\n",
    "    \n",
    "    with open(f\"{filenames_dir_train}\\\\{filename}\", 'rb') as handle:\n",
    "        datas[filename] = json.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define this function which returns the cell to which a player has moved, both absolutely to the general structure (needed to keep track of the player position during the round \"scraping\") and relatively to the cell it is coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_movement(next_position, prev_cell):\n",
    "    next_cell = data_struct.find_closest(next_position[0], next_position[1], next_position[2])[0]\n",
    "    \n",
    "    if prev_cell == next_cell:\n",
    "        return 0, next_cell\n",
    "    \n",
    "    for i, val in enumerate(connect_to[prev_cell]):\n",
    "        if val == next_cell:\n",
    "            return i + 1, next_cell\n",
    "    # Too bad, let's return None\n",
    "\n",
    "    # Hold your horses, maybe he moved a bit\n",
    "    # quick and passed over\n",
    "    # to the second degree neighbor?\n",
    "    for j, other_cell in enumerate(connect_to[prev_cell]):\n",
    "        for i, val2 in enumerate(connect_to[other_cell]):\n",
    "            if val2 == next_cell:\n",
    "                return j + 1, next_cell\n",
    "\n",
    "    # Well now we're not recovering it\n",
    "    return None, next_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the round scraping, essentially we go through each frame (a frame happens every .5 seconds in our parsed .jsons) for each .json's round and keep track of the player's movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movements done: 547761. Of which 6210 bad.\n"
     ]
    }
   ],
   "source": [
    "cell_samples = [list() for _ in range(len(points))]\n",
    "\n",
    "counter = 0\n",
    "bad = 0\n",
    "\n",
    "for filename, data in datas.items():\n",
    "    for round_i, gameRound in enumerate(data[\"gameRounds\"]):\n",
    "        bookkeep_pos = dict()\n",
    "        for frame_i, frame in enumerate(gameRound[\"frames\"]):\n",
    "            if frame[\"ct\"][\"players\"] != None:\n",
    "                for i, player in enumerate(frame[\"ct\"][\"players\"]):\n",
    "                    pos = (player[\"x\"], player[\"y\"], player[\"z\"])\n",
    "                    if (prev_cell := bookkeep_pos.get(player[\"steamID\"], None)) == None:\n",
    "                        bookkeep_pos[player[\"steamID\"]] = data_struct.find_closest(pos[0],pos[1],pos[2])[0]\n",
    "                    else:\n",
    "                        choice, next_cell = actual_movement(pos, prev_cell)\n",
    "\n",
    "                        if choice != None:\n",
    "                            cell_samples[prev_cell].append((filename, round_i, frame_i - 1, \"ct\", player[\"steamID\"], choice))\n",
    "                        else:\n",
    "                            bad += 1\n",
    "                        counter += 1\n",
    "                        bookkeep_pos[player[\"steamID\"]] = next_cell\n",
    "\n",
    "\n",
    "            if frame[\"t\"][\"players\"] != None:\n",
    "                for i, player in enumerate(frame[\"t\"][\"players\"]):\n",
    "                    pos = (player[\"x\"], player[\"y\"], player[\"z\"])\n",
    "                    if (prev_cell := bookkeep_pos.get(player[\"steamID\"], None)) == None:\n",
    "                        bookkeep_pos[player[\"steamID\"]] = data_struct.find_closest(pos[0],pos[1],pos[2])[0]\n",
    "                    else:\n",
    "                        choice, next_cell = actual_movement(pos, prev_cell)\n",
    "\n",
    "                        if choice != None:\n",
    "                            cell_samples[prev_cell].append((filename, round_i, frame_i - 1, \"t\", player[\"steamID\"], choice))\n",
    "                        else:\n",
    "                            bad += 1\n",
    "\n",
    "                        counter += 1\n",
    "                        bookkeep_pos[player[\"steamID\"]] = next_cell\n",
    "\n",
    "with open(middle_result_name_train + \"DONOTOVERWRITE\", 'wb') as handle:\n",
    "    pickle.dump(cell_samples, handle)\n",
    "\n",
    "print(f\"Movements done: {counter}. Of which {bad} bad.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 6210 bads out of 547761? That's nice. How do we define a bad movement? Essentially it is any movement for which our graph is not designed for (special and rare cases for which modeling was really too difficult, we'll explain).\n",
    "\n",
    "Now we actually get our samples, to do so we go through each of the cells we have in the graph and, for it, through each sample for that cell (this is needed since we'll have to build a model for each cell, thus we group the data in this way).\n",
    "\n",
    "For each sample we recover/record the cell from which the player came from, the team it was part of, the number of teammates alive and the average direction his team was with respect to him (you'll see/read that these last two explanatory variables are problematic, anyway we've left them in the files for recording reasons).\n",
    "Of course we also record the cell it went to.\n",
    "\n",
    "Some of these records will not be stored and will be labeled as bad for a multitude of reasons: maybe we didn't design the structure for the movement they did (most of these cases were pruned before) or other reasons came up.\n",
    "\n",
    "#### WARNING THIS CELL TAKES A COUPLE OF MINUTES TO RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541551 7920\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open(middle_result_name_train, 'rb') as handle:\n",
    "    cell_samples = pickle.load(handle)\n",
    "\n",
    "# Actually parsing data\n",
    "recovered_samples = list()\n",
    "total_data = 0\n",
    "bad = 0\n",
    "# Let's now go through every sample\n",
    "for cell_i,samples in enumerate(cell_samples):\n",
    "    cell_dict = {\"choice\": list(), \"cell_from\": list(), \"team\": list(), \"dir_team\": list(), \"n_alive\": list()}\n",
    "\n",
    "    for filename, round_i, frame_i, team, player_id, true_choice in samples:\n",
    "        total_data += 1\n",
    "        if frame_i <= 0:\n",
    "            bad += 1\n",
    "            continue\n",
    "        team_info_before = datas[filename][\"gameRounds\"][round_i][\"frames\"][frame_i - 1][team]\n",
    "        index = None\n",
    "        other_positions = list()\n",
    "        for i, player in enumerate(team_info_before[\"players\"]):\n",
    "            if player[\"steamID\"] == player_id:\n",
    "                index = i\n",
    "            else:\n",
    "                other_positions.append((player[\"x\"], player[\"y\"]))\n",
    "        \n",
    "        if index == None:\n",
    "            bad += 1\n",
    "            continue\n",
    "        player = team_info_before[\"players\"][index]\n",
    "        prev_cell = data_struct.find_closest(player[\"x\"],player[\"y\"],player[\"z\"])[0]\n",
    "        \n",
    "        prev_choice = 0\n",
    "        possible_bad = True\n",
    "\n",
    "        if prev_cell in connect_from[cell_i]:\n",
    "            prev_choice = connect_from[cell_i].index(prev_cell) + 1\n",
    "            possible_bad = False\n",
    "        elif prev_cell == cell_i:\n",
    "            possible_bad = False\n",
    "        \n",
    "        if possible_bad:\n",
    "            for j, other_cell in enumerate(connect_from[cell_i]):\n",
    "                for val2 in connect_from[other_cell]:\n",
    "                    if val2 == prev_cell:\n",
    "                        possible_bad = False\n",
    "                        prev_choice = j + 1\n",
    "                        break\n",
    "                if not possible_bad:\n",
    "                    break\n",
    "\n",
    "        if possible_bad:\n",
    "            bad += 1\n",
    "            continue\n",
    "\n",
    "        angle = 0\n",
    "        if len(other_positions) > 0:\n",
    "            mean_pos = np.mean(np.asarray(other_positions), axis=0)\n",
    "            mean_pos -= np.asarray([player[\"x\"],player[\"y\"]])\n",
    "            angle = np.arctan2(mean_pos[1], mean_pos[0])\n",
    "\n",
    "        cell_dict[\"n_alive\"].append(len(other_positions) + 1)\n",
    "        cell_dict[\"dir_team\"].append(angle)\n",
    "        cell_dict[\"choice\"].append(true_choice)\n",
    "        cell_dict[\"cell_from\"].append(prev_choice)\n",
    "        if team == \"ct\":\n",
    "            cell_dict[\"team\"].append(0)\n",
    "        else:\n",
    "            cell_dict[\"team\"].append(1)\n",
    "\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df[\"cell_from\"] = pd.Categorical(cell_dict[\"cell_from\"], categories=list(range(len(connect_from[cell_i]) + 1)), ordered=False)\n",
    "    temp_df[\"team\"] = pd.Categorical(cell_dict[\"team\"], categories=[0,1], ordered=False)\n",
    "    temp_df[\"n_alive\"] = pd.Categorical(cell_dict[\"n_alive\"], categories=list(range(1,6)), ordered=False)\n",
    "    temp_df[\"dir_team\"] = cell_dict[\"dir_team\"]\n",
    "    temp_df[\"choice\"] = cell_dict[\"choice\"]\n",
    "    recovered_samples.append(temp_df)\n",
    "\n",
    "\n",
    "print(total_data, bad)\n",
    "\n",
    "with open(final_result_name_train + \"DONOTOVERWRITE\", 'wb') as handle:\n",
    "    pickle.dump(recovered_samples, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the results for the data we'll use to *train* (to regress) our model, as you can see again the number of bad samples is pretty low with respect to how many samples we've looked at, huge success!\n",
    "\n",
    "\n",
    "Now we extract the data for testing, since we want to predict player's positions in a 5 seconds timeline (10 frames in our .jsons), we'll have to use slightly different code in the final part.\n",
    "\n",
    "Again we load the jsons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ence-vs-natus-vincere-m2-dust2.json\n",
      "Loading ex-uyu-vs-unjustified-m2-dust2.json\n",
      "Loading faze-vs-spirit-m2-dust2.json\n",
      "Loading finest-vs-cloudrunners-dust2.json\n",
      "Loading shape-vs-babos-m1-dust2.json\n",
      "Loading stone-vs-leviatan-dust2.json\n"
     ]
    }
   ],
   "source": [
    "filenames_test = os.listdir(filenames_dir_test)\n",
    "\n",
    "datas_test = dict()\n",
    "\n",
    "for filename in filenames_test:\n",
    "    name, ext = os.path.splitext(filename)\n",
    "\n",
    "    if ext != \".json\":\n",
    "        continue\n",
    "\n",
    "    print(f\"Loading {filename}\")\n",
    "    \n",
    "    with open(f\"{filenames_dir_test}\\\\{filename}\", 'rb') as handle:\n",
    "        datas_test[filename] = json.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run it through the scraper as before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movements done: 398074. Of which 4506 bad.\n"
     ]
    }
   ],
   "source": [
    "cell_samples_test = [list() for _ in range(len(points))]\n",
    "\n",
    "counter = 0\n",
    "bad = 0\n",
    "\n",
    "for filename, data in datas_test.items():\n",
    "    for round_i, gameRound in enumerate(data[\"gameRounds\"]):\n",
    "        bookkeep_pos = dict()\n",
    "        for frame_i, frame in enumerate(gameRound[\"frames\"]):\n",
    "            if frame[\"ct\"][\"players\"] != None:\n",
    "                for i, player in enumerate(frame[\"ct\"][\"players\"]):\n",
    "                    pos = (player[\"x\"], player[\"y\"], player[\"z\"])\n",
    "                    if (prev_cell := bookkeep_pos.get(player[\"steamID\"], None)) == None:\n",
    "                        bookkeep_pos[player[\"steamID\"]] = data_struct.find_closest(pos[0],pos[1],pos[2])[0]\n",
    "                    else:\n",
    "                        choice, next_cell = actual_movement(pos, prev_cell)\n",
    "\n",
    "                        if choice != None:\n",
    "                            cell_samples_test[prev_cell].append((filename, round_i, frame_i - 1, \"ct\", player[\"steamID\"], choice))\n",
    "                        else:\n",
    "                            bad += 1\n",
    "                        counter += 1\n",
    "                        bookkeep_pos[player[\"steamID\"]] = next_cell\n",
    "\n",
    "\n",
    "            if frame[\"t\"][\"players\"] != None:\n",
    "                for i, player in enumerate(frame[\"t\"][\"players\"]):\n",
    "                    pos = (player[\"x\"], player[\"y\"], player[\"z\"])\n",
    "                    if (prev_cell := bookkeep_pos.get(player[\"steamID\"], None)) == None:\n",
    "                        bookkeep_pos[player[\"steamID\"]] = data_struct.find_closest(pos[0],pos[1],pos[2])[0]\n",
    "                    else:\n",
    "                        choice, next_cell = actual_movement(pos, prev_cell)\n",
    "\n",
    "                        if choice != None:\n",
    "                            cell_samples_test[prev_cell].append((filename, round_i, frame_i - 1, \"t\", player[\"steamID\"], choice))\n",
    "                        else:\n",
    "                            bad += 1\n",
    "\n",
    "                        counter += 1\n",
    "                        bookkeep_pos[player[\"steamID\"]] = next_cell\n",
    "\n",
    "with open(middle_result_name_test  + \"DONOTOVERWRITE\", 'wb') as handle:\n",
    "    pickle.dump(cell_samples_test, handle)\n",
    "\n",
    "print(f\"Movements done: {counter}. Of which {bad} bad.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have fewer movements for the testing (six games instead of the ten used before!), anyway we can observe that the number of \"bad\"s is again pretty low.\n",
    "\n",
    "We now go through code (similar to the one used for the recovery of regression data) to get the explanatory variables, the only difference is that now we also store some data for multiple frames (a list of 10 values instead of a single number).\n",
    "\n",
    "#### WARNING THIS CELL TAKES 5 MINUTES TO RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393568 47745\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open(middle_result_name_test, 'rb') as handle:\n",
    "    cell_samples_test = pickle.load(handle)\n",
    "\n",
    "# Actually parsing data\n",
    "recovered_samples = list()\n",
    "total_data = 0\n",
    "bad = 0\n",
    "\n",
    "# Let's now go through every sample\n",
    "for cell_i,samples in enumerate(cell_samples_test):\n",
    "    cell_dict = {\"cell_from\": list(), \"team\": list(), \"course\": list(), \"n_alive_lst\": list(), \"dir_team_lst\": list()}\n",
    "\n",
    "    for filename, round_i, frame_i, team, player_id, true_choice in samples:\n",
    "        total_data += 1\n",
    "        if frame_i <= 0:\n",
    "            bad += 1\n",
    "            continue\n",
    "\n",
    "        team_info_before = datas_test[filename][\"gameRounds\"][round_i][\"frames\"][frame_i - 1][team]\n",
    "        index = None\n",
    "        for i, player in enumerate(team_info_before[\"players\"]):\n",
    "            if player[\"steamID\"] == player_id:\n",
    "                index = i\n",
    "                break\n",
    "        \n",
    "        if index == None:\n",
    "            bad += 1\n",
    "            continue\n",
    "        player = team_info_before[\"players\"][index]\n",
    "        prev_cell = data_struct.find_closest(player[\"x\"],player[\"y\"],player[\"z\"])[0]\n",
    "\n",
    "        \n",
    "        prev_choice = 0\n",
    "        possible_bad = True\n",
    "        if prev_cell in connect_from[cell_i]:\n",
    "            prev_choice = connect_from[cell_i].index(prev_cell) + 1\n",
    "            possible_bad = False\n",
    "        elif prev_cell == cell_i:\n",
    "            possible_bad = False\n",
    "        \n",
    "        if possible_bad:\n",
    "            for j, other_cell in enumerate(connect_from[cell_i]):\n",
    "                for val2 in connect_from[other_cell]:\n",
    "                    if val2 == prev_cell:\n",
    "                        possible_bad = False\n",
    "                        prev_choice = j + 1\n",
    "                        break\n",
    "                if not possible_bad:\n",
    "                    break\n",
    "\n",
    "        if possible_bad:\n",
    "            bad += 1\n",
    "            continue\n",
    "        \n",
    "        course = []\n",
    "        angles = []\n",
    "        n_alives = []\n",
    "        get_data_frame = frame_i + 10\n",
    "        if get_data_frame < len(datas_test[filename][\"gameRounds\"][round_i][\"frames\"]):\n",
    "            bad_one = False\n",
    "            prev_cell = cell_i\n",
    "            for frame_k in range(frame_i, get_data_frame + 1):\n",
    "                team_info_curr = datas_test[filename][\"gameRounds\"][round_i][\"frames\"][frame_k][team]\n",
    "                \n",
    "                index = None\n",
    "                other_positions = list()\n",
    "                try:\n",
    "                    for i, player in enumerate(team_info_curr[\"players\"]):\n",
    "                        if player[\"steamID\"] == player_id:\n",
    "                            index = i\n",
    "                        else:\n",
    "                            other_positions.append((player[\"x\"], player[\"y\"]))\n",
    "                except:\n",
    "                    bad_one = True\n",
    "                    break\n",
    "                if index == None:\n",
    "                    bad_one = True\n",
    "                    break\n",
    "\n",
    "                player = team_info_curr[\"players\"][index]\n",
    "\n",
    "                mov, next_cell = actual_movement((player[\"x\"],player[\"y\"],player[\"z\"]), prev_cell)\n",
    "\n",
    "                if mov == None:\n",
    "                    bad_one = True\n",
    "                    break\n",
    "\n",
    "                angle = 0\n",
    "                if len(other_positions) > 0:\n",
    "                    mean_pos = np.mean(np.asarray(other_positions), axis=0)\n",
    "                    mean_pos -= np.asarray([player[\"x\"],player[\"y\"]])\n",
    "                    angle = np.arctan2(mean_pos[1], mean_pos[0])\n",
    "\n",
    "                angles.append(angle)\n",
    "                n_alives.append(len(other_positions) + 1)\n",
    "                course.append(next_cell)\n",
    "                prev_cell = next_cell\n",
    "\n",
    "            \n",
    "            if bad_one:\n",
    "                bad += 1\n",
    "                continue\n",
    "        else:\n",
    "            bad += 1\n",
    "            continue\n",
    "\n",
    "\n",
    "        cell_dict[\"n_alive_lst\"].append(n_alives)\n",
    "        cell_dict[\"dir_team_lst\"].append(angles)\n",
    "        cell_dict[\"course\"].append(course)\n",
    "        cell_dict[\"cell_from\"].append(prev_choice)\n",
    "        if team == \"ct\":\n",
    "            cell_dict[\"team\"].append(0)\n",
    "        else:\n",
    "            cell_dict[\"team\"].append(1)\n",
    "\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df[\"cell_from\"] = pd.Categorical(cell_dict[\"cell_from\"], categories=list(range(len(connect_from[cell_i]) + 1)), ordered=False)\n",
    "    temp_df[\"team\"] = pd.Categorical(cell_dict[\"team\"], categories=[0,1], ordered=False)\n",
    "    temp_df[\"n_alive_lst\"] = [pd.Categorical(lst, categories=list(range(1,6)), ordered=False) for lst in cell_dict[\"n_alive_lst\"]]\n",
    "    temp_df[\"dir_team_lst\"] = cell_dict[\"dir_team_lst\"]\n",
    "    temp_df[\"course\"] = cell_dict[\"course\"]\n",
    "    recovered_samples.append(temp_df)\n",
    "\n",
    "print(total_data, bad)\n",
    "\n",
    "with open(final_result_name_test  + \"DONOTOVERWRITE\", 'wb') as handle:\n",
    "    pickle.dump(recovered_samples, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh wow, 47745 \"bad\" samples? This may seem a bit much, but we assure you the reason is simple: it's not like the design we did is unable (as happened in the previous cases) to nicely represent the events.\n",
    "In this case the problem stems from the fact that we count as \"bad\" the cases in which we are unable to gain all full 5 seconds of information about the player: thus, if something happens to him such that the data is not present (simplest case: the player dies in that timeframe) then we must discard the sample.\n",
    "\n",
    "At any rate the number of good samples is still extremely high, so we do not worry of this number."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f57e34485fb6a85143dc4c12b9c228dde6caba3425587afa0276cc3c8562532"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
